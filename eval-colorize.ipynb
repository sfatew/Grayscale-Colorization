{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-19T17:48:36.808841Z",
     "iopub.status.busy": "2025-04-19T17:48:36.808534Z",
     "iopub.status.idle": "2025-04-19T17:48:37.029138Z",
     "shell.execute_reply": "2025-04-19T17:48:37.028372Z",
     "shell.execute_reply.started": "2025-04-19T17:48:36.808819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:48:37.030900Z",
     "iopub.status.busy": "2025-04-19T17:48:37.030648Z",
     "iopub.status.idle": "2025-04-19T17:48:41.937769Z",
     "shell.execute_reply": "2025-04-19T17:48:41.936867Z",
     "shell.execute_reply.started": "2025-04-19T17:48:37.030879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:48:41.939142Z",
     "iopub.status.busy": "2025-04-19T17:48:41.938865Z",
     "iopub.status.idle": "2025-04-19T17:48:41.943053Z",
     "shell.execute_reply": "2025-04-19T17:48:41.942500Z",
     "shell.execute_reply.started": "2025-04-19T17:48:41.939111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:48:41.944883Z",
     "iopub.status.busy": "2025-04-19T17:48:41.944680Z",
     "iopub.status.idle": "2025-04-19T17:48:54.572916Z",
     "shell.execute_reply": "2025-04-19T17:48:54.572355Z",
     "shell.execute_reply.started": "2025-04-19T17:48:41.944868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import torch.nn.functional as F\n",
    "#from torch.distributions import Categorical\n",
    "\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import time\n",
    "\n",
    "import wandb\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:48:54.573963Z",
     "iopub.status.busy": "2025-04-19T17:48:54.573650Z",
     "iopub.status.idle": "2025-04-19T17:48:54.578108Z",
     "shell.execute_reply": "2025-04-19T17:48:54.577465Z",
     "shell.execute_reply.started": "2025-04-19T17:48:54.573940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_set_root='/kaggle/input/coco-2017-dataset/coco2017'\n",
    "train_set ='train2017'\n",
    "validation_set ='val2017'\n",
    "test_set = 'test2017'\n",
    "\n",
    "train_path = os.path.join(data_set_root, train_set)\n",
    "\n",
    "val_path = os.path.join(data_set_root, validation_set)\n",
    "\n",
    "test_path = os.path.join(data_set_root, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:48:54.579316Z",
     "iopub.status.busy": "2025-04-19T17:48:54.579046Z",
     "iopub.status.idle": "2025-04-19T17:54:58.668513Z",
     "shell.execute_reply": "2025-04-19T17:54:58.667893Z",
     "shell.execute_reply.started": "2025-04-19T17:48:54.579292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_image_path = list(Path(train_path).rglob(\"*.*\"))\n",
    "val_image_path = list(Path(val_path).rglob(\"*.*\"))\n",
    "test_image_path = list(Path(test_path).rglob(\"*.*\"))\n",
    "\n",
    "print(len(train_image_path), len(val_image_path), len(test_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:58.669448Z",
     "iopub.status.busy": "2025-04-19T17:54:58.669212Z",
     "iopub.status.idle": "2025-04-19T17:54:59.016971Z",
     "shell.execute_reply": "2025-04-19T17:54:59.016174Z",
     "shell.execute_reply.started": "2025-04-19T17:54:58.669429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(train_image_path[1])\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.018174Z",
     "iopub.status.busy": "2025-04-19T17:54:59.017955Z",
     "iopub.status.idle": "2025-04-19T17:54:59.021794Z",
     "shell.execute_reply": "2025-04-19T17:54:59.021132Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.018151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.022676Z",
     "iopub.status.busy": "2025-04-19T17:54:59.022431Z",
     "iopub.status.idle": "2025-04-19T17:54:59.056175Z",
     "shell.execute_reply": "2025-04-19T17:54:59.055679Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.022655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the 313 quantized color bins\n",
    "pts_in_hull = np.load('/kaggle/input/colorful-image-colorization-parameters/pts_in_hull.npy')  # shape (313, 2), each is an (a, b) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.058460Z",
     "iopub.status.busy": "2025-04-19T17:54:59.058278Z",
     "iopub.status.idle": "2025-04-19T17:54:59.276998Z",
     "shell.execute_reply": "2025-04-19T17:54:59.276411Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.058446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def soft_encode_ab(ab_image, pts_in_hull, sigma=5):\n",
    "    \"\"\"\n",
    "    ab_image: torch tensor of shape (2, H, W)\n",
    "    pts_in_hull: numpy array of shape (313, 2)\n",
    "    returns: soft encoding of shape (H, W, 313)\n",
    "    \"\"\"\n",
    "    C, H, W = ab_image.shape\n",
    "    assert C == 2, \"Expected input with 2 channels (a and b)\"\n",
    "\n",
    "    # Convert to (H, W, 2)\n",
    "    ab_image = ab_image.permute(1, 2, 0)\n",
    "    ab_flat = ab_image.reshape(-1, 2).cpu().numpy()\n",
    "    \n",
    "    # Nearest neighbors search\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(pts_in_hull)\n",
    "    dists, inds = nbrs.kneighbors(ab_flat)\n",
    "\n",
    "    # Gaussian kernel\n",
    "    dists = np.clip(dists, 0, 30)\n",
    "    weights = np.exp(-dists**2 / (2 * sigma**2))\n",
    "    \n",
    "    weights_sum = np.sum(weights, axis=1, keepdims=True)\n",
    "    weights_sum[weights_sum == 0] = 1e-8  # prevent div by zero\n",
    "    \n",
    "    weights /= weights_sum #normalize\n",
    "\n",
    "    # Soft encoding\n",
    "    soft_enc = np.zeros((ab_flat.shape[0], 313), dtype=np.float32)\n",
    "    for i in range(5):\n",
    "        soft_enc[np.arange(ab_flat.shape[0]), inds[:, i]] = weights[:, i]\n",
    "\n",
    "    # Reshape back to (H, W, 313)\n",
    "    return torch.from_numpy(soft_enc).reshape(H, W, 313)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.277789Z",
     "iopub.status.busy": "2025-04-19T17:54:59.277588Z",
     "iopub.status.idle": "2025-04-19T17:54:59.284855Z",
     "shell.execute_reply": "2025-04-19T17:54:59.284142Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.277773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, Size=(224, 224), transform=None, pts_in_hull = None):\n",
    "        self.paths = paths\n",
    "        self.height, self.width = Size\n",
    "        self.transform = transform\n",
    "        self.pts_in_hull = pts_in_hull\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = img.resize((self.height, self.width), Image.BICUBIC)\n",
    "        img = np.array(img)  # Convert PIL to NumPy (Albumentations requires NumPy)\n",
    "\n",
    "        # Apply Albumentations transform if provided\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "\n",
    "        # If img is in (C, H, W) format, convert to (H, W, C)\n",
    "        if img.shape[0] == 3:\n",
    "            img = np.transpose(img, (1, 2, 0))  # Convert (C, H, W) → (H, W, C)\n",
    "\n",
    "        # Convert RGB → LAB\n",
    "        img_lab = rgb2lab(img).astype(\"float32\")  # (H, W, 3)\n",
    "\n",
    "        # Extract L and ab channels\n",
    "        L = img_lab[:, :, 0] \n",
    "        ab = img_lab[:, :, 1:]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        L = torch.tensor(L, dtype=torch.float32).unsqueeze(0)  # (1, H, W)\n",
    "        ab = torch.tensor(ab, dtype=torch.float32).permute(2, 0, 1)  # (2, H, W)\n",
    "\n",
    "        # ab: [2, H, W] ground truth ab channels\n",
    "        ab_downsampled = F.interpolate(\n",
    "            ab.unsqueeze(0),  # Add batch dim -> shape: [1, 2, H, W]\n",
    "            scale_factor=0.25,\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)  # Remove batch dim -> back to [2, H/4, W/4]  \n",
    "\n",
    "        # Soft encode ab (call external function)\n",
    "        soft_encoded = soft_encode_ab(ab_image = ab_downsampled, pts_in_hull = self.pts_in_hull)  # (H/4, W/4, 313), NumPy\n",
    "        soft_encoded = soft_encoded.float().permute(2, 0, 1)  # To Tensor (313, H/4, W/4)\n",
    "\n",
    "        return {'L': L, 'ab': ab, 'soft_ab': soft_encoded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.285780Z",
     "iopub.status.busy": "2025-04-19T17:54:59.285508Z",
     "iopub.status.idle": "2025-04-19T17:54:59.307274Z",
     "shell.execute_reply": "2025-04-19T17:54:59.306745Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.285760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.4),\n",
    "    A.VerticalFlip(p=0.4),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), p=0.2),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.308830Z",
     "iopub.status.busy": "2025-04-19T17:54:59.308086Z",
     "iopub.status.idle": "2025-04-19T17:54:59.325189Z",
     "shell.execute_reply": "2025-04-19T17:54:59.324631Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.308812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=False, **kwargs): # A handy function to make our dataloaders\n",
    "    dataset = ColorizationDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                            pin_memory=pin_memory)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.326069Z",
     "iopub.status.busy": "2025-04-19T17:54:59.325798Z",
     "iopub.status.idle": "2025-04-19T17:54:59.341069Z",
     "shell.execute_reply": "2025-04-19T17:54:59.340357Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.326052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = make_dataloaders(batch_size = batch_size, pin_memory=True, paths=train_image_path, transform = transform, pts_in_hull = pts_in_hull)\n",
    "\n",
    "val_loader = make_dataloaders(batch_size = batch_size, pin_memory=True, paths=val_image_path, pts_in_hull = pts_in_hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:54:59.342100Z",
     "iopub.status.busy": "2025-04-19T17:54:59.341832Z",
     "iopub.status.idle": "2025-04-19T17:55:00.486918Z",
     "shell.execute_reply": "2025-04-19T17:55:00.486137Z",
     "shell.execute_reply.started": "2025-04-19T17:54:59.342085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "Ls, abs_ = data['L'], data['soft_ab']\n",
    "print(Ls.shape, abs_.shape)\n",
    "print(len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.488095Z",
     "iopub.status.busy": "2025-04-19T17:55:00.487844Z",
     "iopub.status.idle": "2025-04-19T17:55:00.492799Z",
     "shell.execute_reply": "2025-04-19T17:55:00.492091Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.488079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaseColor(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(BaseColor, self).__init__()\n",
    "\n",
    "\t\tself.l_cent = 50.\n",
    "\t\tself.l_norm = 100.\n",
    "\t\tself.ab_norm = 110.\n",
    "\n",
    "\tdef normalize_l(self, in_l):\n",
    "\t\treturn (in_l-self.l_cent)/self.l_norm   # Normalize L to [-0.5, 0.5]\n",
    "\n",
    "\tdef unnormalize_l(self, in_l):\n",
    "\t\treturn in_l*self.l_norm + self.l_cent\n",
    "\n",
    "\tdef normalize_ab(self, in_ab):\n",
    "\t\treturn in_ab/self.ab_norm    # Normalize ab to [-1, 1]\n",
    "\n",
    "\tdef unnormalize_ab(self, in_ab):\n",
    "\t\treturn in_ab*self.ab_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.493795Z",
     "iopub.status.busy": "2025-04-19T17:55:00.493541Z",
     "iopub.status.idle": "2025-04-19T17:55:00.511836Z",
     "shell.execute_reply": "2025-04-19T17:55:00.510847Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.493779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ColorizationNet(BaseColor):\n",
    "    def __init__(self, norm_layer=nn.BatchNorm2d):\n",
    "        super(ColorizationNet, self).__init__()\n",
    "\n",
    "        model1=[nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model1+=[nn.ReLU(True),]\n",
    "        model1+=[norm_layer(64),]\n",
    "\n",
    "        model2=[nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model2+=[nn.ReLU(True),]\n",
    "        model2+=[norm_layer(128),]\n",
    "\n",
    "        model3=[nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1, bias=True),]\n",
    "        model3+=[nn.ReLU(True),]\n",
    "        model3+=[norm_layer(256),]\n",
    "\n",
    "        model4=[nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model4+=[nn.ReLU(True),]\n",
    "        model4+=[norm_layer(512),]\n",
    "\n",
    "        model5=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model5+=[nn.ReLU(True),]\n",
    "        model5+=[norm_layer(512),]\n",
    "\n",
    "        model6=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=True),]\n",
    "        model6+=[nn.ReLU(True),]\n",
    "        model6+=[norm_layer(512),]\n",
    "\n",
    "        model7=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model7+=[nn.ReLU(True),]\n",
    "        model7+=[norm_layer(512),]\n",
    "\n",
    "        model8=[nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=True),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "        model8+=[nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=True),]\n",
    "        model8+=[nn.ReLU(True),]\n",
    "\n",
    "        model8+=[nn.Conv2d(256, 313, kernel_size=1, stride=1, padding=0, bias=True),]\n",
    "\n",
    "        self.model1 = nn.Sequential(*model1)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        self.model3 = nn.Sequential(*model3)\n",
    "        self.model4 = nn.Sequential(*model4)\n",
    "        self.model5 = nn.Sequential(*model5)\n",
    "        self.model6 = nn.Sequential(*model6)\n",
    "        self.model7 = nn.Sequential(*model7)\n",
    "        self.model8 = nn.Sequential(*model8)\n",
    "\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "        #self.model_out = nn.Conv2d(313, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=False)\n",
    "        #self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear')\n",
    "\n",
    "    def forward(self, input_l):\n",
    "        conv1_2 = self.model1(self.normalize_l(input_l))\n",
    "        conv2_2 = self.model2(conv1_2)\n",
    "        conv3_3 = self.model3(conv2_2)\n",
    "        conv4_3 = self.model4(conv3_3)\n",
    "        conv5_3 = self.model5(conv4_3)\n",
    "        conv6_3 = self.model6(conv5_3)\n",
    "        conv7_3 = self.model7(conv6_3)\n",
    "        conv8_3 = self.model8(conv7_3)\n",
    "        #out_reg = self.model_out(self.softmax(conv8_3))\n",
    "\n",
    "        #return self.unnormalize_ab(self.upsample4(out_reg))\n",
    "        #return self.softmax(conv8_3)\n",
    "        return conv8_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.512852Z",
     "iopub.status.busy": "2025-04-19T17:55:00.512618Z",
     "iopub.status.idle": "2025-04-19T17:55:00.529967Z",
     "shell.execute_reply": "2025-04-19T17:55:00.529485Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.512828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.531347Z",
     "iopub.status.busy": "2025-04-19T17:55:00.531162Z",
     "iopub.status.idle": "2025-04-19T17:55:00.546348Z",
     "shell.execute_reply": "2025-04-19T17:55:00.545722Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.531333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_model(device):\n",
    "    model = ColorizationNet()\n",
    "    model.apply(init_weights)\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.547231Z",
     "iopub.status.busy": "2025-04-19T17:55:00.547015Z",
     "iopub.status.idle": "2025-04-19T17:55:00.559769Z",
     "shell.execute_reply": "2025-04-19T17:55:00.559210Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.547216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.560613Z",
     "iopub.status.busy": "2025-04-19T17:55:00.560439Z",
     "iopub.status.idle": "2025-04-19T17:55:00.653534Z",
     "shell.execute_reply": "2025-04-19T17:55:00.652884Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.560600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.655155Z",
     "iopub.status.busy": "2025-04-19T17:55:00.654835Z",
     "iopub.status.idle": "2025-04-19T17:55:00.666803Z",
     "shell.execute_reply": "2025-04-19T17:55:00.666191Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.655131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "\n",
    "epochs = 160\n",
    "\n",
    "model_path = '/kaggle/working/model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:00.667846Z",
     "iopub.status.busy": "2025-04-19T17:55:00.667544Z",
     "iopub.status.idle": "2025-04-19T17:55:01.352228Z",
     "shell.execute_reply": "2025-04-19T17:55:01.351659Z",
     "shell.execute_reply.started": "2025-04-19T17:55:00.667822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = create_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:01.353116Z",
     "iopub.status.busy": "2025-04-19T17:55:01.352910Z",
     "iopub.status.idle": "2025-04-19T17:55:01.357731Z",
     "shell.execute_reply": "2025-04-19T17:55:01.357122Z",
     "shell.execute_reply.started": "2025-04-19T17:55:01.353101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:13.911884Z",
     "iopub.status.busy": "2025-04-19T17:55:13.911650Z",
     "iopub.status.idle": "2025-04-19T17:55:13.917211Z",
     "shell.execute_reply": "2025-04-19T17:55:13.916594Z",
     "shell.execute_reply.started": "2025-04-19T17:55:13.911868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas = (0.9, 0.99), weight_decay = 1e-3)\n",
    "\n",
    "scaler = GradScaler()  # Mixed Precision Training\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:13.918126Z",
     "iopub.status.busy": "2025-04-19T17:55:13.917907Z",
     "iopub.status.idle": "2025-04-19T17:55:13.933948Z",
     "shell.execute_reply": "2025-04-19T17:55:13.933121Z",
     "shell.execute_reply.started": "2025-04-19T17:55:13.918112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def cross_entropy_with_soft_targets(pred_logits, soft_targets, pixel_weights=None):\n",
    "    \"\"\"\n",
    "    pred_logits: (B, 313, H, W) — model outputs (logits)\n",
    "    soft_targets: (B, 313, H, W) — soft-encoded targets\n",
    "    pixel_weights: (B, H, W) — optional pixel-wise weighting\n",
    "    \"\"\"\n",
    "    log_preds = F.log_softmax(pred_logits, dim=1)  # (B, 313, H, W)\n",
    "    log_preds = torch.clamp(log_preds, min=-100)  # prevent -inf\n",
    "\n",
    "    # Element-wise product and sum over channels\n",
    "    loss = -(soft_targets * log_preds).sum(dim=1)  # (B, H, W)\n",
    "\n",
    "    if pixel_weights is not None:\n",
    "        loss = loss * pixel_weights  # (B, H, W)\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:13.934881Z",
     "iopub.status.busy": "2025-04-19T17:55:13.934679Z",
     "iopub.status.idle": "2025-04-19T17:55:13.953673Z",
     "shell.execute_reply": "2025-04-19T17:55:13.952945Z",
     "shell.execute_reply.started": "2025-04-19T17:55:13.934866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_rebalance_weights(p, Q=313, lam=0.5):\n",
    "    \"\"\"\n",
    "    p: numpy array of shape (313,), empirical distribution over color bins\n",
    "    returns: weight array of shape (313,)\n",
    "    \"\"\"\n",
    "    mixed = (1 - lam) * p + lam / Q\n",
    "    w = 1 / mixed\n",
    "    w *= 1 / np.sum(w * p)  # normalize to expected value 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:55:13.954809Z",
     "iopub.status.busy": "2025-04-19T17:55:13.954542Z",
     "iopub.status.idle": "2025-04-19T17:55:13.980384Z",
     "shell.execute_reply": "2025-04-19T17:55:13.979917Z",
     "shell.execute_reply.started": "2025-04-19T17:55:13.954789Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load or compute your prior (e.g., empirical distribution of 313 bins)\n",
    "prior_probs = np.load('/kaggle/input/colorful-image-colorization-parameters/prior_probs.npy')  # shape: (313,)\n",
    "rebalance_weights = compute_rebalance_weights(prior_probs)  # shape: (313,)\n",
    "rebalance_weights = torch.tensor(rebalance_weights, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:56:14.985903Z",
     "iopub.status.busy": "2025-04-19T17:56:14.985146Z",
     "iopub.status.idle": "2025-04-19T17:56:14.990822Z",
     "shell.execute_reply": "2025-04-19T17:56:14.990111Z",
     "shell.execute_reply.started": "2025-04-19T17:56:14.985877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inverse_weights = compute_rebalance_weights(prior_probs, Q=313, lam=0)\n",
    "inverse_weights = torch.tensor(inverse_weights, dtype=torch.float32).to(device)  # (313,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:56:17.308585Z",
     "iopub.status.busy": "2025-04-19T17:56:17.308134Z",
     "iopub.status.idle": "2025-04-19T17:56:17.314158Z",
     "shell.execute_reply": "2025-04-19T17:56:17.313471Z",
     "shell.execute_reply.started": "2025-04-19T17:56:17.308561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_pixel_weight(soft_label, weights):\n",
    "    \"\"\"\n",
    "    soft_label: (B, 313, H, W) soft encoding tensor\n",
    "    weights: (313,) numpy array or tensor\n",
    "    returns: (B, H, W) tensor of pixel weights\n",
    "    \"\"\"\n",
    "    if soft_label.dim() != 4 or soft_label.shape[1] != 313:\n",
    "        raise ValueError(f\"Expected shape (B, 313, H, W), got {soft_label.shape}\")\n",
    "\n",
    "    # Move channel to last dimension: (B, H, W, 313)\n",
    "    soft_label = soft_label.permute(0, 2, 3, 1)\n",
    "\n",
    "    max_idx = torch.argmax(soft_label, dim=3)  # (B, H, W)\n",
    "\n",
    "    if isinstance(weights, np.ndarray):\n",
    "        weight_tensor = torch.from_numpy(weights).to(soft_label.device)\n",
    "    else:\n",
    "        weight_tensor = weights.to(soft_label.device)\n",
    "\n",
    "    return weight_tensor[max_idx]  # (B, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:56:19.197989Z",
     "iopub.status.busy": "2025-04-19T17:56:19.197295Z",
     "iopub.status.idle": "2025-04-19T17:56:19.203003Z",
     "shell.execute_reply": "2025-04-19T17:56:19.202375Z",
     "shell.execute_reply.started": "2025-04-19T17:56:19.197965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def soft_to_ab(soft_map, color_bins):\n",
    "    \"\"\"\n",
    "    soft_map: (B, 313, H, W) — soft probability over quantized bins\n",
    "    color_bins: (313, 2) — ab values for each quantized bin\n",
    "    Returns:\n",
    "        ab_map: (B, 2, H, W)\n",
    "    \"\"\"\n",
    "    B, _, H, W = soft_map.shape\n",
    "    color_bins = torch.tensor(color_bins, dtype=soft_map.dtype, device=soft_map.device)  # (313, 2)\n",
    "\n",
    "    # reshape softmap to (B, H, W, 313), then do a weighted sum along 313\n",
    "    soft_map = soft_map.permute(0, 2, 3, 1)  # (B, H, W, 313)\n",
    "    ab_map = torch.matmul(soft_map, color_bins)  # (B, H, W, 2)\n",
    "    ab_map = ab_map.permute(0, 3, 1, 2)  # (B, 2, H, W)\n",
    "    return ab_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:56:21.365877Z",
     "iopub.status.busy": "2025-04-19T17:56:21.365293Z",
     "iopub.status.idle": "2025-04-19T17:56:21.372331Z",
     "shell.execute_reply": "2025-04-19T17:56:21.371745Z",
     "shell.execute_reply.started": "2025-04-19T17:56:21.365853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_class_balanced_auc(pred_ab, true_ab, inverse_weights, pts_in_hull, max_thresh=150):\n",
    "    \"\"\"\n",
    "    pred_ab, true_ab: (B, 2, H, W)\n",
    "    color_freq: (313,) normalized class frequency\n",
    "    \"\"\"\n",
    "    # Compute L2 distance per pixel\n",
    "    l2_error = torch.linalg.norm(pred_ab - true_ab, dim=1)   # (B, H, W)\n",
    "    error_flat = l2_error.flatten().cpu().numpy()\n",
    "\n",
    "    # Inverse class weights\n",
    "    weight = inverse_weights\n",
    "\n",
    "    # Get the class for each pixel based on true_ab (use clustering or quantization)\n",
    "    true_ab_exp = true_ab.permute(0, 2, 3, 1).reshape(-1, 2).cpu().numpy()\n",
    "    \n",
    "    # Compute L2 distance to cluster centers\n",
    "    diff = true_ab_exp[:, None, :] - pts_in_hull[None, :, :]  # (47040, 313, 2)\n",
    "    dist = np.linalg.norm(diff, axis=2)  # (47040, 313)\n",
    "\n",
    "    bin_ids = np.argmin(dist, axis=1)  # Find the closest bin for each pixel\n",
    "\n",
    "    # Use the class ids (bin_ids) to get the corresponding weight\n",
    "    weighted_error = weight[bin_ids]\n",
    "    weighted_error = weighted_error.cpu().numpy() \n",
    "    total_weight = weighted_error.sum() + 1e-6  # avoid divide-by-zero\n",
    "\n",
    "    # Compute the CDF: cumulative distribution of errors weighted by class importance\n",
    "    thresholds = np.arange(0, max_thresh + 1)\n",
    "    cdf = []\n",
    "    \n",
    "    for t in thresholds:\n",
    "        \n",
    "        # Calculate cumulative weighted sum for pixels where error < threshold t\n",
    "        cdf_value = weighted_error[error_flat < t].sum()\n",
    "        cdf.append(cdf_value/ total_weight)\n",
    "\n",
    "    # Normalize the CDF and compute AUC\n",
    "    cdf = np.array(cdf)\n",
    "    auc = np.trapz(cdf, thresholds) / max_thresh\n",
    "\n",
    "    return auc, thresholds, cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-19T17:55:14.043946Z",
     "iopub.status.idle": "2025-04-19T17:55:14.044222Z",
     "shell.execute_reply": "2025-04-19T17:55:14.044117Z",
     "shell.execute_reply.started": "2025-04-19T17:55:14.044104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def annealed_mean(prob, pts_in_hull, T=0.38):\n",
    "    \"\"\"\n",
    "    prob: (H, W, 313), predicted softmax probabilities\n",
    "    pts_in_hull: (313, 2)\n",
    "    returns: ab image of shape (H, W, 2)\n",
    "    \"\"\"\n",
    "    prob = prob ** (1 / T)\n",
    "    prob /= np.sum(prob, axis=2, keepdims=True)\n",
    "    ab = np.dot(prob, pts_in_hull)  # weighted mean\n",
    "    return ab  # shape (H, W, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T17:56:33.358797Z",
     "iopub.status.busy": "2025-04-19T17:56:33.358274Z",
     "iopub.status.idle": "2025-04-19T18:06:08.785772Z",
     "shell.execute_reply": "2025-04-19T18:06:08.784897Z",
     "shell.execute_reply.started": "2025-04-19T17:56:33.358767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "\n",
    "def validate(model, data_loader, rebalance_weights, inverse_weights, pts_in_hull, device):\n",
    "    model.eval()\n",
    "    ssim_vals = []\n",
    "    psnr_vals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            L = batch['L'].to(device)  # (B, 1, H, W)\n",
    "            ab_gt = batch['ab'].to(device)  # (B, 2, H, W)\n",
    "\n",
    "            outputs = model(L)  # (B, 313, H/4, W/4)\n",
    "\n",
    "            logits_upsampled = F.interpolate(outputs, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "\n",
    "            pred_soft = torch.softmax(logits_upsampled, dim=1)\n",
    "\n",
    "            # Convert softmax predictions to ab\n",
    "            pred_ab = annealed_mean(pred_soft, pts_in_hull)  # (B, 2, H, W)\n",
    "            true_ab = ab_gt  # (B, 2, H, W)\n",
    "\n",
    "            # Convert L + ab to LAB and then to RGB for SSIM/PSNR\n",
    "            L_np = L.cpu().numpy()\n",
    "            pred_ab_np = pred_ab.cpu().numpy()\n",
    "            true_ab_np = true_ab.cpu().numpy()\n",
    "\n",
    "            for i in range(L_np.shape[0]):\n",
    "                # Prepare LAB images\n",
    "                L_img = L_np[i, 0]\n",
    "                pred_ab_img = pred_ab_np[i].transpose(1, 2, 0)\n",
    "                true_ab_img = true_ab_np[i].transpose(1, 2, 0)\n",
    "\n",
    "                # Unnormalize\n",
    "                L_img = (L_img + 0) \n",
    "                pred_lab = np.zeros((L_img.shape[0], L_img.shape[1], 3))\n",
    "                pred_lab[:, :, 0] = L_img\n",
    "                pred_lab[:, :, 1:] = pred_ab_img\n",
    "                true_lab = np.zeros_like(pred_lab)\n",
    "                true_lab[:, :, 0] = L_img\n",
    "                true_lab[:, :, 1:] = true_ab_img\n",
    "\n",
    "                # Convert to RGB\n",
    "                pred_rgb = lab2rgb(pred_lab)\n",
    "                true_rgb = lab2rgb(true_lab)\n",
    "\n",
    "                # Compute SSIM and PSNR\n",
    "                ssim_val = ssim(true_rgb, pred_rgb, data_range=1.0, channel_axis=2)\n",
    "                psnr_val = psnr(true_rgb, pred_rgb, data_range=1.0)\n",
    "                ssim_vals.append(ssim_val)\n",
    "                psnr_vals.append(psnr_val)\n",
    "\n",
    "    mean_ssim = float(np.mean(ssim_vals))\n",
    "    mean_psnr = float(np.mean(psnr_vals))\n",
    "    return mean_ssim, mean_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_ssim, val_psnr = validate(model, val_loader, rebalance_weights, inverse_weights, pts_in_hull, device)\n",
    "print(f\"Validation SSIM: {val_ssim:.4f}, PSNR: {val_psnr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2198658,
     "sourceId": 3673319,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
